# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.14.5
#   kernelspec:
#     display_name: Python 3 (ipykernel)
#     language: python
#     name: python3
# ---

# + [markdown] id="gEJNiFMuxa6x"
# # ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ë²•ì˜ Prediction

# + executionInfo={"elapsed": 6, "status": "ok", "timestamp": 1651652211296, "user": {"displayName": "Jungi Kim", "userId": "13599710065611566056"}, "user_tz": -540} id="dL09IfYlxAz3"
import numpy as np
from tqdm import tqdm


# + [markdown] id="_QybMndKxW52"
# ## ê·¸ë¦¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜

# + executionInfo={"elapsed": 4, "status": "ok", "timestamp": 1651652211296, "user": {"displayName": "Jungi Kim", "userId": "13599710065611566056"}, "user_tz": -540} id="8kriUlj0xWee"
# V table ê·¸ë¦¬ê¸°    
def show_v_table(v_table, env):    
    for i in range(env.reward.shape[0]):        
        print("+-----------------"*env.reward.shape[1],end="")
        print("+")
        for k in range(3):
            print("|",end="")
            for j in range(env.reward.shape[1]):
                if k==0:
                    print("                 |",end="")
                if k==1:
                        print("   {0:8.2f}      |".format(v_table[i,j]),end="")
                if k==2:
                    print("                 |",end="")
            print()
    print("+-----------------"*env.reward.shape[1],end="")
    print("+")


# + [markdown] id="lgsQsky3w9nQ"
# ## Environment êµ¬í˜„

# + executionInfo={"elapsed": 12, "status": "ok", "timestamp": 1651652211879, "user": {"displayName": "Jungi Kim", "userId": "13599710065611566056"}, "user_tz": -540} id="j-5_IGGDw6dI"
class Environment():
    
    # 1. ë¯¸ë¡œë°–(ì ˆë²½), ê¸¸, ëª©ì ì§€ì™€ ë³´ìƒ ì„¤ì •
    cliff = -3
    road = -1
    goal = 1
    
    # 2. ëª©ì ì§€ ì¢Œí‘œ ì„¤ì •
    goal_position = [2,2]
    
    # 3. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ ìˆ«ì
    reward_list = [[road,road,road],
                   [road,road,road],
                   [road,road,goal]]
    
    # 4. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ ë¬¸ì
    reward_list1 = [["road","road","road"],
                    ["road","road","road"],
                    ["road","road","goal"]]
    
    # 5. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ë¥¼ arrayë¡œ ì„¤ì •
    def __init__(self):
        self.reward = np.asarray(self.reward_list)    

    # 6. ì„ íƒëœ ì—ì´ì „íŠ¸ì˜ í–‰ë™ ê²°ê³¼ ë°˜í™˜ (ë¯¸ë¡œë°–ì¼ ê²½ìš° ì´ì „ ì¢Œí‘œë¡œ ë‹¤ì‹œ ë³µê·€)
    def move(self, agent, action):
        
        done = False
        
        # 6.1 í–‰ë™ì— ë”°ë¥¸ ì¢Œí‘œ êµ¬í•˜ê¸°
        new_pos = agent.pos + agent.action[action]
        
        # 6.2 í˜„ì¬ì¢Œí‘œê°€ ëª©ì ì§€ ì¸ì§€í™•ì¸
        if self.reward_list1[agent.pos[0]][agent.pos[1]] == "goal":
            reward = self.goal
            observation = agent.set_pos(agent.pos)
            done = True
        # 6.3 ì´ë™ í›„ ì¢Œí‘œê°€ ë¯¸ë¡œ ë°–ì¸ í™•ì¸    
        elif new_pos[0] < 0 or new_pos[0] >= self.reward.shape[0] or new_pos[1] < 0 or new_pos[1] >= self.reward.shape[1]:
            reward = self.cliff
            observation = agent.set_pos(agent.pos)
            done = True
        # 6.4 ì´ë™ í›„ ì¢Œí‘œê°€ ê¸¸ì´ë¼ë©´
        else:
            observation = agent.set_pos(new_pos)
            reward = self.reward[observation[0],observation[1]]
            
        return observation, reward, done


# + [markdown] id="tT7seyk7xIBs"
# ## Agent êµ¬í˜„

# + executionInfo={"elapsed": 13, "status": "ok", "timestamp": 1651652211880, "user": {"displayName": "Jungi Kim", "userId": "13599710065611566056"}, "user_tz": -540} id="XK7_RCYNxJyr"
class Agent():
    
    # 1. í–‰ë™ì— ë”°ë¥¸ ì—ì´ì „íŠ¸ì˜ ì¢Œí‘œ ì´ë™(ìœ„, ì˜¤ë¥¸ìª½, ì•„ë˜, ì™¼ìª½) 
    action = np.array([[-1,0],[0,1],[1,0],[0,-1]])
    
    # 2. ê° í–‰ë™ë³„ ì„ íƒí™•ë¥ 
    select_action_pr = np.array([0.25,0.25,0.25,0.25])
    
    # 3. ì—ì´ì „íŠ¸ì˜ ì´ˆê¸° ìœ„ì¹˜ ì €ì¥
    def __init__(self):
        self.pos = (0,0)
    
    # 4. ì—ì´ì „íŠ¸ì˜ ìœ„ì¹˜ ì €ì¥
    def set_pos(self,position):
        self.pos = position
        return self.pos
    
    # 5. ì—ì´ì „íŠ¸ì˜ ìœ„ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
    def get_pos(self):
        return self.pos


# + [markdown] id="-RrVAIaox27F"
# ## ì—í”¼ì†Œë“œ ìƒì„± í•¨ìˆ˜

# + executionInfo={"elapsed": 13, "status": "ok", "timestamp": 1651652211881, "user": {"displayName": "Jungi Kim", "userId": "13599710065611566056"}, "user_tz": -540} id="OopZxTb4wSTK"
def generate_episode(env, agent, first_visit):
    gamma = 0.09
    # ì—í”¼ì†Œë“œë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    episode = []
    # ì´ì „ì— ë°©ë¬¸ì—¬ë¶€ ì²´í¬
    visit = np.zeros((env.reward.shape[0], env.reward.shape[1]))
    
    # ì—ì´ì „íŠ¸ê°€ ëª¨ë“  ìƒíƒœì—ì„œ ì¶œë°œí•  ìˆ˜ ìˆê²Œ ì¶œë°œì§€ì ì„ ë¬´ì‘ìœ„ë¡œ ì„¤ì •
    i = np.random.randint(0,env.reward.shape[0])
    j = np.random.randint(0,env.reward.shape[1])
    agent.set_pos([i,j])    
    #ì—í”¼ì†Œë“œì˜ ìˆ˜ìµì„ ì´ˆê¸°í™”
    G = 0
    #ê°ì‡„ìœ¨ì˜ ì§€ìˆ˜
    step = 0
    max_step = 100
    # ì—í”¼ì†Œë“œ ìƒì„±
    for k in range(max_step):
        pos = agent.get_pos()            
        action = np.random.randint(0,len(agent.action))            
        observaetion, reward, done = env.move(agent, action)    
        
        if first_visit:
            # ì—í”¼ì†Œë“œì— ì²« ë°©ë¬¸í•œ ìƒíƒœì¸ì§€ ê²€ì‚¬ :
            # visit[pos[0],pos[1]] == 0 : ì²« ë°©ë¬¸
            # visit[pos[0],pos[1]] == 1 : ì¤‘ë³µ ë°©ë¬¸
            if visit[pos[0],pos[1]] == 0:   
                # ì—í”¼ì†Œë“œê°€ ëë‚ ë•Œê¹Œì§€ Gë¥¼ ê³„ì‚°
                G += gamma**(step) * reward        
                # ë°©ë¬¸ ì´ë ¥ í‘œì‹œ
                visit[pos[0],pos[1]] = 1
                step += 1               
                # ë°©ë¬¸ ì´ë ¥ ì €ì¥(ìƒíƒœ, í–‰ë™, ë³´ìƒ)
                episode.append((pos,action, reward))
        else:
            G += gamma**(step) * reward
            step += 1                   
            episode.append((pos,action,reward))            

        # ì—í”¼ì†Œë“œê°€ ì¢…ë£Œí–ˆë‹¤ë©´ ë£¨í”„ì—ì„œ íƒˆì¶œ
        if done == True:                
            break        
            
    return i, j, G, episode


# + [markdown] id="gQtwLOM2qpLZ"
# ## First-visit and Every-Visit MC Prediction

# + colab={"base_uri": "https://localhost:8080/"} executionInfo={"elapsed": 59318, "status": "ok", "timestamp": 1651652271187, "user": {"displayName": "Jungi Kim", "userId": "13599710065611566056"}, "user_tz": -540} id="Y90PiuNxwwWm" outputId="5897567a-5771-407c-883b-0912725a13ae"
# first-visit MC and every-visit MC prediction
np.random.seed(0)
# í™˜ê²½, ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”
env = Environment()
agent = Agent()

# ì„ì˜ì˜ ìƒíƒœ ê°€ì¹˜ í•¨ìˆ˜ğ‘‰
v_table = np.zeros((env.reward.shape[0], env.reward.shape[1]))

# ìƒíƒœë³„ë¡œ ì—í”¼ì†Œë“œ ì¶œë°œíšŸìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”
v_start = np.zeros((env.reward.shape[0], env.reward.shape[1]))

# ìƒíƒœë³„ë¡œ ë„ì°©ì§€ì  ë„ì°©íšŸìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”
v_success = np.zeros((env.reward.shape[0], env.reward.shape[1]))

# ğ‘…ğ‘’ğ‘¡ğ‘¢ğ‘Ÿğ‘›(ğ‘ )â†ë¹ˆ ë¦¬ìŠ¤íŠ¸ (ëª¨ë“  sâˆˆğ‘†ì— ëŒ€í•´)
Return_s = [[[] for j in range(env.reward.shape[1])] for i in range(env.reward.shape[0])]

# ìµœëŒ€ ì—í”¼ì†Œë“œ ìˆ˜ë¥¼ ì§€ì •
max_episode = 100000

# first visit ë¥¼ ì‚¬ìš©í• ì§€ every visitë¥¼ ì‚¬ìš©í•  ì§€ ê²°ì •
# first_visit = True : first visit
# first_visit = False : every visit
first_visit = False
if first_visit:
    print("start first visit MC")
else : 
    print("start every visit MC")
print()

for epi in tqdm(range(max_episode)):
    
    i,j,G,episode = generate_episode(env, agent, first_visit)
    
    # ìˆ˜ìµ ğºë¥¼ ğ‘…ğ‘’ğ‘¡ğ‘¢ğ‘Ÿğ‘›(ğ‘ )ì— ì¶”ê°€(append)
    Return_s[i][j].append(G)
    
    # ì—í”¼ì†Œë“œ ë°œìƒ íšŸìˆ˜ ê³„ì‚°
    episode_count = len(Return_s[i][j])
    # ìƒíƒœë³„ ë°œìƒí•œ ìˆ˜ìµì˜ ì´í•© ê³„ì‚°
    total_G = np.sum(Return_s[i][j])
    # ìƒíƒœë³„ ë°œìƒí•œ ìˆ˜ìµì˜ í‰ê·  ê³„ì‚°
    v_table[i,j] = total_G / episode_count
    
  # ë„ì°©ì§€ì ì— ë„ì°©(reward = 1)í–ˆëŠ”ì§€ ì²´í¬    
    # episode[-1][2] : ì—í”¼ì†Œë“œ ë§ˆì§€ë§‰ ìƒíƒœì˜ ë³´ìƒ
    if episode[-1][2] == 1:
        v_success[i,j] += 1

# ì—í”¼ì†Œë“œ ì¶œë°œ íšŸìˆ˜ ì €ì¥ 
for i in range(env.reward.shape[0]):
    for j in range(env.reward.shape[1]):
        v_start[i,j] = len(Return_s[i][j])
        
print("V(s)")
show_v_table(np.round(v_table,2),env)
print("V_start_count(s)")
show_v_table(np.round(v_start,2),env)
print("V_success_pr(s)")
show_v_table(np.round(v_success/v_start,2),env)
