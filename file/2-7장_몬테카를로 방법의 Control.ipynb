{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2-7ì¥_ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ë²•ì˜ Control.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMlpB0rfF7kSywlqLSj+nY8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ë²•ì˜ Control"],"metadata":{"id":"gEJNiFMuxa6x"}},{"cell_type":"code","source":["import numpy as np\n","from tqdm import tqdm"],"metadata":{"id":"dL09IfYlxAz3","executionInfo":{"status":"ok","timestamp":1651296571271,"user_tz":-540,"elapsed":359,"user":{"displayName":"Jungi Kim","userId":"13599710065611566056"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["##ê·¸ë¦¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜"],"metadata":{"id":"_QybMndKxW52"}},{"cell_type":"code","source":["# Q table ê·¸ë¦¬ê¸°\n","def show_q_table(q_table,env):\n","    for i in range(env.reward.shape[0]):\n","        print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n","        print(\"+\")\n","        for k in range(3):\n","            print(\"|\",end=\"\")\n","            for j in range(env.reward.shape[1]):\n","                if k==0:\n","                    print(\"{0:10.2f}       |\".format(q_table[i,j,0]),end=\"\")\n","                if k==1:\n","                    print(\"{0:6.2f}    {1:6.2f} |\".format(q_table[i,j,3],q_table[i,j,1]),end=\"\")\n","                if k==2:\n","                    print(\"{0:10.2f}       |\".format(q_table[i,j,2]),end=\"\")\n","            print()\n","    print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n","    print(\"+\")\n","\n","# ì •ì±… policy í™”ì‚´í‘œë¡œ ê·¸ë¦¬ê¸°\n","def show_policy(policy,env):\n","    for i in range(env.reward.shape[0]):        \n","        print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n","        print(\"+\")\n","        for k in range(3):\n","            print(\"|\",end=\"\")\n","            for j in range(env.reward.shape[1]):\n","                if k==0:\n","                    print(\"                 |\",end=\"\")\n","                if k==1:\n","                    if policy[i,j] == 0:\n","                        print(\"      â†‘         |\",end=\"\")\n","                    elif policy[i,j] == 1:\n","                        print(\"      â†’         |\",end=\"\")\n","                    elif policy[i,j] == 2:\n","                        print(\"      â†“         |\",end=\"\")\n","                    elif policy[i,j] == 3:\n","                        print(\"      â†         |\",end=\"\")\n","                if k==2:\n","                    print(\"                 |\",end=\"\")\n","            print()\n","    print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n","    print(\"+\")"],"metadata":{"id":"8kriUlj0xWee","executionInfo":{"status":"ok","timestamp":1651296571969,"user_tz":-540,"elapsed":12,"user":{"displayName":"Jungi Kim","userId":"13599710065611566056"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["##Environment êµ¬í˜„"],"metadata":{"id":"lgsQsky3w9nQ"}},{"cell_type":"code","source":["class Environment():\n","    \n","    # 1. ë¯¸ë¡œë°–(ì ˆë²½), ê¸¸, ëª©ì ì§€ì™€ ë³´ìƒ ì„¤ì •\n","    cliff = -3\n","    road = -1\n","    goal = 1\n","    \n","    # 2. ëª©ì ì§€ ì¢Œí‘œ ì„¤ì •\n","    goal_position = [2,2]\n","    \n","    # 3. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ ìˆ«ì\n","    reward_list = [[road,road,road],\n","                   [road,road,road],\n","                   [road,road,goal]]\n","    \n","    # 4. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ ë¬¸ì\n","    reward_list1 = [[\"road\",\"road\",\"road\"],\n","                    [\"road\",\"road\",\"road\"],\n","                    [\"road\",\"road\",\"goal\"]]\n","    \n","    # 5. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ë¥¼ arrayë¡œ ì„¤ì •\n","    def __init__(self):\n","        self.reward = np.asarray(self.reward_list)    \n","\n","    # 6. ì„ íƒëœ ì—ì´ì „íŠ¸ì˜ í–‰ë™ ê²°ê³¼ ë°˜í™˜ (ë¯¸ë¡œë°–ì¼ ê²½ìš° ì´ì „ ì¢Œí‘œë¡œ ë‹¤ì‹œ ë³µê·€)\n","    def move(self, agent, action):\n","        \n","        done = False\n","        \n","        # 6.1 í–‰ë™ì— ë”°ë¥¸ ì¢Œí‘œ êµ¬í•˜ê¸°\n","        new_pos = agent.pos + agent.action[action]\n","        \n","        # 6.2 í˜„ì¬ì¢Œí‘œê°€ ëª©ì ì§€ ì¸ì§€í™•ì¸\n","        if self.reward_list1[agent.pos[0]][agent.pos[1]] == \"goal\":\n","            reward = self.goal\n","            observation = agent.set_pos(agent.pos)\n","            done = True\n","        # 6.3 ì´ë™ í›„ ì¢Œí‘œê°€ ë¯¸ë¡œ ë°–ì¸ í™•ì¸    \n","        elif new_pos[0] < 0 or new_pos[0] >= self.reward.shape[0] or new_pos[1] < 0 or new_pos[1] >= self.reward.shape[1]:\n","            reward = self.cliff\n","            observation = agent.set_pos(agent.pos)\n","            done = True\n","        # 6.4 ì´ë™ í›„ ì¢Œí‘œê°€ ê¸¸ì´ë¼ë©´\n","        else:\n","            observation = agent.set_pos(new_pos)\n","            reward = self.reward[observation[0],observation[1]]\n","            \n","        return observation, reward, done"],"metadata":{"id":"j-5_IGGDw6dI","executionInfo":{"status":"ok","timestamp":1651296571970,"user_tz":-540,"elapsed":12,"user":{"displayName":"Jungi Kim","userId":"13599710065611566056"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["##Agent êµ¬í˜„"],"metadata":{"id":"tT7seyk7xIBs"}},{"cell_type":"code","source":["class Agent():\n","    \n","    # 1. í–‰ë™ì— ë”°ë¥¸ ì—ì´ì „íŠ¸ì˜ ì¢Œí‘œ ì´ë™(ìœ„, ì˜¤ë¥¸ìª½, ì•„ë˜, ì™¼ìª½) \n","    action = np.array([[-1,0],[0,1],[1,0],[0,-1]])\n","    \n","    # 2. ê° í–‰ë™ë³„ ì„ íƒí™•ë¥ \n","    select_action_pr = np.array([0.25,0.25,0.25,0.25])\n","    \n","    # 3. ì—ì´ì „íŠ¸ì˜ ì´ˆê¸° ìœ„ì¹˜ ì €ì¥\n","    def __init__(self):\n","        self.pos = (0,0)\n","    \n","    # 4. ì—ì´ì „íŠ¸ì˜ ìœ„ì¹˜ ì €ì¥\n","    def set_pos(self,position):\n","        self.pos = position\n","        return self.pos\n","    \n","    # 5. ì—ì´ì „íŠ¸ì˜ ìœ„ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n","    def get_pos(self):\n","        return self.pos"],"metadata":{"id":"XK7_RCYNxJyr","executionInfo":{"status":"ok","timestamp":1651296571970,"user_tz":-540,"elapsed":11,"user":{"displayName":"Jungi Kim","userId":"13599710065611566056"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["##ì—í”¼ì†Œë“œ ìƒì„± í•¨ìˆ˜"],"metadata":{"id":"-RrVAIaox27F"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"OopZxTb4wSTK","executionInfo":{"status":"ok","timestamp":1651296571971,"user_tz":-540,"elapsed":11,"user":{"displayName":"Jungi Kim","userId":"13599710065611566056"}}},"outputs":[],"source":["def generate_episode_with_policy(env, agent, first_visit, policy):\n","    gamma = 0.09\n","    # ì—í”¼ì†Œë“œë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n","    episode = []\n","    # ì´ì „ì— ë°©ë¬¸ì—¬ë¶€ ì²´í¬\n","    visit = np.zeros((env.reward.shape[0], env.reward.shape[1],len(agent.action)))\n","    \n","    # ì—ì´ì „íŠ¸ëŠ” í•­ìƒ (0,0)ì—ì„œ ì¶œë°œ\n","    i = 0\n","    j = 0\n","    agent.set_pos([i,j])    \n","    #ì—í”¼ì†Œë“œì˜ ìˆ˜ìµì„ ì´ˆê¸°í™”\n","    G = 0\n","    #ê°ì‡„ìœ¨ì˜ ì§€ìˆ˜\n","    step = 0\n","    max_step = 100\n","    # ì—í”¼ì†Œë“œ ìƒì„±\n","    for k in range(max_step):\n","        pos = agent.get_pos()        \n","        # í˜„ì¬ ìƒíƒœì˜ ì •ì±…ì„ ì´ìš©í•´ í–‰ë™ì„ ì„ íƒí•œ í›„ ì´ë™\n","        action = np.random.choice(range(0,len(agent.action)), p=policy[pos[0],pos[1],:]) \n","        observaetion, reward, done = env.move(agent, action)    \n","        \n","        if first_visit:\n","            # ì—í”¼ì†Œë“œì— ì²« ë°©ë¬¸í•œ ìƒíƒœì¸ì§€ ê²€ì‚¬ :\n","            # visit[pos[0],pos[1]] == 0 : ì²« ë°©ë¬¸\n","            # visit[pos[0],pos[1]] == 1 : ì¤‘ë³µ ë°©ë¬¸\n","            if visit[pos[0],pos[1],action] == 0:   \n","                # ì—í”¼ì†Œë“œê°€ ëë‚ ë•Œê¹Œì§€ Gë¥¼ ê³„ì‚°\n","                G += gamma**(step) * reward        \n","                # ë°©ë¬¸ ì´ë ¥ í‘œì‹œ\n","                visit[pos[0],pos[1],action] = 1\n","                step += 1               \n","                # ë°©ë¬¸ ì´ë ¥ ì €ì¥(ìƒíƒœ, í–‰ë™, ë³´ìƒ)\n","                episode.append((pos,action, reward))\n","        else:\n","            G += gamma**(step) * reward\n","            step += 1                   \n","            episode.append((pos,action,reward))            \n","\n","        # ì—í”¼ì†Œë“œê°€ ì¢…ë£Œí–ˆë‹¤ë©´ ë£¨í”„ì—ì„œ íƒˆì¶œ\n","        if done == True:                \n","            break        \n","            \n","    return i, j, G, episode"]},{"cell_type":"markdown","source":["Ïµ-ì •ì±…ì„ ì´ìš©í•˜ëŠ” ëª¬í…Œì¹´ë¥¼ë¡œ control ì•Œê³ ë¦¬ì¦˜"],"metadata":{"id":"gQtwLOM2qpLZ"}},{"cell_type":"code","source":["np.random.seed(0)\n","# í™˜ê²½, ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”\n","env = Environment()\n","agent = Agent()\n","\n","# ëª¨ë“  ğ‘ âˆˆğ‘†,ğ‘âˆˆğ´(ğ‘†)ì— ëŒ€í•´ ì´ˆê¸°í™”:\n","# # ğ‘„(ğ‘ ,ğ‘)â†ì„ì˜ì˜ ê°’ (í–‰ë™ ê°œìˆ˜, ë¯¸ë¡œ ì„¸ë¡œ, ë¯¸ë¡œ ê°€ë¡œ)\n","Q_table = np.random.rand(env.reward.shape[0], env.reward.shape[1],len(agent.action))\n","print(\"Initial Q(s,a)\")\n","show_q_table(Q_table,env)\n","\n","# ìƒíƒœë¥¼ ë°©ë¬¸í•œ íšŸìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”\n","Q_visit = np.zeros((env.reward.shape[0], env.reward.shape[1],len(agent.action)))\n","\n","# ë¯¸ë¡œ ëª¨ë“  ìƒíƒœì—ì„œ ìµœì  í–‰ë™ì„ ì €ì¥í•˜ëŠ” í…Œì´ë¸”\n","# ê° ìƒíƒœì—ì„œ Q ê°’ì´ ê°€ì¥ í° í–‰ë™ì„ ì„ íƒ í›„ optimal_a ì— ì €ì¥\n","optimal_a = np.zeros((env.reward.shape[0],env.reward.shape[1]))\n","for i in range(env.reward.shape[0]):\n","    for j in range(env.reward.shape[1]):\n","        optimal_a[i,j] = np.argmax(Q_table[i,j,:])\n","print(\"initial optimal_a\")\n","show_policy(optimal_a,env)\n","\n","# Ï€(ğ‘ ,ğ‘)â†ì„ì˜ì˜ ğœ–âˆ’íƒìš• ì •ì±…\n","# ë¬´ì‘ìœ„ë¡œ í–‰ë™ì„ ì„ íƒí•˜ë„ë¡ ì§€ì •\n","policy = np.zeros((env.reward.shape[0], env.reward.shape[1],len(agent.action)))\n","\n","# í•œ ìƒíƒœì—ì„œ ê°€ëŠ¥í•œ í™•ë¥ ì˜ í•©ì´ 1ì´ ë˜ë„ë¡ ê³„ì‚°\n","epsilon = 0.8\n","for i in range(env.reward.shape[0]):\n","    for j in range(env.reward.shape[1]):\n","        for k in range(len(agent.action)):\n","            if optimal_a[i,j] == k:\n","                policy[i,j,k] = 1 - epsilon + epsilon/len(agent.action)\n","            else:\n","                policy[i,j,k] = epsilon/len(agent.action)\n","print(\"Initial Policy\")\n","show_q_table(policy,env)\n","\n","\n","# ìµœëŒ€ ì—í”¼ì†Œë“œ ìˆ˜ ê¸¸ì´ë¥¼ ì§€ì •\n","max_episode = 10000\n","\n","# first visit ë¥¼ ì‚¬ìš©í• ì§€ every visitë¥¼ ì‚¬ìš©í•  ì§€ ê²°ì •\n","# first_visit = True : first visit\n","# first_visit = False : every visit\n","first_visit = True\n","if first_visit:\n","    print(\"start first visit MC\")\n","else : \n","    print(\"start every visit MC\")\n","print()\n","\n","gamma = 0.09\n","for epi in tqdm(range(max_episode)):\n","# for epi in range(max_episode):\n","\n","    # Ï€ë¥¼ ì´ìš©í•´ì„œ ì—í”¼ì†Œë“œ 1ê°œë¥¼ ìƒì„±\n","    x,y,G,episode = generate_episode_with_policy(env, agent, first_visit, policy)\n","    \n","    for step_num in range(len(episode)):\n","        G = 0\n","        # episode[step_num][0][0] : step_numë²ˆì§¸ ë°©ë¬¸í•œ ìƒíƒœì˜ x ì¢Œí‘œ\n","        # episode[step_num][0][1] : step_numë²ˆì§¸ ë°©ë¬¸í•œ ìƒíƒœì˜ y ì¢Œí‘œ\n","        # episode[step_num][1] : step_numë²ˆì§¸ ìƒíƒœì—ì„œ ì„ íƒí•œ í–‰ë™\n","        i = episode[step_num][0][0]\n","        j = episode[step_num][0][1]\n","        action = episode[step_num][1]\n","        \n","        # ì—í”¼ì†Œë“œ ì‹œì‘ì ì„ ì¹´ìš´íŠ¸\n","        Q_visit[i,j,action] += 1\n","\n","        # ì„œë¸Œ ì—í”¼ì†Œë“œ (episode[step_num:])ì˜ ì¶œë°œë¶€í„° ëê¹Œì§€ ìˆ˜ìµ Gë¥¼ ê³„ì‚°\n","        # k[2] : episode[step_num][2] ê³¼ ê°™ìœ¼ë©° step_num ë²ˆì§¸ ë°›ì€ ë³´ìƒ\n","        # step : ê°ì‡„ìœ¨\n","        for step, k in enumerate(episode[step_num:]):\n","            G += gamma**(step)*k[2]\n","\n","        # Incremental mean : ğ‘„(ğ‘ ,ğ‘)â†ğ‘ğ‘£ğ‘’ğ‘Ÿğ‘ğ‘”ğ‘’(ğ‘…ğ‘’ğ‘¡ğ‘¢ğ‘Ÿğ‘›(ğ‘ ,ğ‘)) \n","        Q_table[i,j,action] += 1 / Q_visit[i,j,action]*(G-Q_table[i,j,action])\n","    \n","    # (c) ì—í”¼ì†Œë“œ ì•ˆì˜ ê° sì— ëŒ€í•´ì„œ :\n","    # ë¯¸ë¡œ ëª¨ë“  ìƒíƒœì—ì„œ ìµœì  í–‰ë™ì„ ì €ì¥í•  ê³µê°„ ë§ˆë ¨\n","    # ğ‘âˆ— â†argmax_a ğ‘„(ğ‘ ,ğ‘)\n","    for i in range(env.reward.shape[0]):\n","        for j in range(env.reward.shape[1]):\n","            optimal_a[i,j] = np.argmax(Q_table[i,j,:])            \n","   \n","    # ëª¨ë“  ğ‘âˆˆğ´(ğ‘†) ì— ëŒ€í•´ì„œ :\n","    # ìƒˆë¡œ ê³„ì‚°ëœ optimal_a ë¥¼ ì´ìš©í•´ì„œ í–‰ë™ ì„ íƒ í™•ë¥  policy (Ï€) ê°±ì‹ \n","    epsilon = 1 - epi/max_episode\n","\n","    for i in range(env.reward.shape[0]):\n","        for j in range(env.reward.shape[1]):\n","            for k in range(len(agent.action)):\n","                if optimal_a[i,j] == k:\n","                    policy[i,j,k] = 1 - epsilon + epsilon/len(agent.action)\n","                else:\n","                    policy[i,j,k] = epsilon/len(agent.action)\n","\n","print(\"Final Q(s,a)\")\n","show_q_table(Q_table,env)\n","print(\"Final policy\")\n","show_q_table(policy,env)\n","print(\"Final optimal_a\")\n","show_policy(optimal_a,env)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y90PiuNxwwWm","executionInfo":{"status":"ok","timestamp":1651296575122,"user_tz":-540,"elapsed":3162,"user":{"displayName":"Jungi Kim","userId":"13599710065611566056"}},"outputId":"ed7d6d9f-4a10-4db4-8d0f-ed4f7dee3f8e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial Q(s,a)\n","+-----------------+-----------------+-----------------+\n","|      0.55       |      0.42       |      0.96       |\n","|  0.54      0.72 |  0.89      0.65 |  0.53      0.38 |\n","|      0.60       |      0.44       |      0.79       |\n","+-----------------+-----------------+-----------------+\n","|      0.57       |      0.02       |      0.98       |\n","|  0.09      0.93 |  0.87      0.83 |  0.78      0.80 |\n","|      0.07       |      0.78       |      0.46       |\n","+-----------------+-----------------+-----------------+\n","|      0.12       |      0.52       |      0.46       |\n","|  0.94      0.64 |  0.77      0.41 |  0.62      0.57 |\n","|      0.14       |      0.26       |      0.02       |\n","+-----------------+-----------------+-----------------+\n","initial optimal_a\n","+-----------------+-----------------+-----------------+\n","|                 |                 |                 |\n","|      â†’         |      â†         |      â†‘         |\n","|                 |                 |                 |\n","+-----------------+-----------------+-----------------+\n","|                 |                 |                 |\n","|      â†’         |      â†         |      â†‘         |\n","|                 |                 |                 |\n","+-----------------+-----------------+-----------------+\n","|                 |                 |                 |\n","|      â†         |      â†         |      â†         |\n","|                 |                 |                 |\n","+-----------------+-----------------+-----------------+\n","Initial Policy\n","+-----------------+-----------------+-----------------+\n","|      0.20       |      0.20       |      0.40       |\n","|  0.20      0.40 |  0.40      0.20 |  0.20      0.20 |\n","|      0.20       |      0.20       |      0.20       |\n","+-----------------+-----------------+-----------------+\n","|      0.20       |      0.20       |      0.40       |\n","|  0.20      0.40 |  0.40      0.20 |  0.20      0.20 |\n","|      0.20       |      0.20       |      0.20       |\n","+-----------------+-----------------+-----------------+\n","|      0.20       |      0.20       |      0.20       |\n","|  0.40      0.20 |  0.40      0.20 |  0.40      0.20 |\n","|      0.20       |      0.20       |      0.20       |\n","+-----------------+-----------------+-----------------+\n","start first visit MC\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:03<00:00, 3270.13it/s]"]},{"output_type":"stream","name":"stdout","text":["Final Q(s,a)\n","+-----------------+-----------------+-----------------+\n","|     -3.00       |     -3.00       |     -3.00       |\n","| -3.00     -1.13 | -1.17     -1.16 | -1.13     -3.00 |\n","|     -1.12       |     -1.09       |     -1.02       |\n","+-----------------+-----------------+-----------------+\n","|     -1.17       |     -1.13       |     -1.14       |\n","| -3.00     -1.09 | -1.12     -0.96 | -1.03     -3.00 |\n","|     -1.15       |     -1.02       |      1.09       |\n","+-----------------+-----------------+-----------------+\n","|     -1.14       |     -1.08       |      1.00       |\n","| -3.00     -1.01 | -1.14      1.09 |  1.00      1.00 |\n","|     -3.00       |     -3.00       |      1.00       |\n","+-----------------+-----------------+-----------------+\n","Final policy\n","+-----------------+-----------------+-----------------+\n","|      0.00       |      0.00       |      0.00       |\n","|  0.00      0.00 |  0.00      0.00 |  0.00      0.00 |\n","|      1.00       |      1.00       |      1.00       |\n","+-----------------+-----------------+-----------------+\n","|      0.00       |      0.00       |      0.00       |\n","|  0.00      1.00 |  0.00      1.00 |  0.00      0.00 |\n","|      0.00       |      0.00       |      1.00       |\n","+-----------------+-----------------+-----------------+\n","|      0.00       |      0.00       |      1.00       |\n","|  0.00      1.00 |  0.00      1.00 |  0.00      0.00 |\n","|      0.00       |      0.00       |      0.00       |\n","+-----------------+-----------------+-----------------+\n","Final optimal_a\n","+-----------------+-----------------+-----------------+\n","|                 |                 |                 |\n","|      â†“         |      â†“         |      â†“         |\n","|                 |                 |                 |\n","+-----------------+-----------------+-----------------+\n","|                 |                 |                 |\n","|      â†’         |      â†’         |      â†“         |\n","|                 |                 |                 |\n","+-----------------+-----------------+-----------------+\n","|                 |                 |                 |\n","|      â†’         |      â†’         |      â†‘         |\n","|                 |                 |                 |\n","+-----------------+-----------------+-----------------+\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}